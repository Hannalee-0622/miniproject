{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a857b1d7",
   "metadata": {},
   "source": [
    "### ê°€ìƒ í™˜ê²½ í™œì„±í™”\n",
    "\n",
    "1. ì›í•˜ëŠ” í´ë”ë¡œ ì´ë™  \n",
    "```cd C:\\Users\\user-name\\your-directory-path```\n",
    "  \n",
    "<br>  \n",
    "\n",
    "2. ê°€ìƒí™˜ê²½ ìƒì„±  \n",
    "```python -m venv huggingface-env```\n",
    "  \n",
    "<br>  \n",
    "\n",
    "3. ê°€ìƒí™˜ê²½ í™œì„±í™”   \n",
    "```.\\huggingface-env\\Scripts\\activate```\n",
    "\n",
    "<br>  \n",
    ">  í™œì„±í™”ë˜ë©´ í”„ë¡¬í”„íŠ¸ê°€ (huggingface-env)ë¡œ ë°”ë€ë‹ˆë‹¤.\n",
    "\n",
    "<br>  \n",
    "\n",
    "+) ê°€ìƒí™˜ê²½ ë¹„í™œì„±í™”:  \n",
    "```deactivate```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592977d2",
   "metadata": {},
   "source": [
    "### requirements.txt. ì„¤ì¹˜\n",
    "\n",
    "ê°€ìƒ í™˜ê²½ì´ í™œì„±í™”ê°€ ë˜ì—ˆìœ¼ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ëª¨ë“ˆ ì„¤ì¹˜:  \n",
    "\n",
    "```pip install -r requirements.txt```\n",
    "\n",
    "\n",
    "ë§Œì•½, ì—ëŸ¬ê°€ ë°œìƒí•œë‹¤ë©´ pip ìµœì‹ í™” ë¨¼ì € ì‹¤í–‰:  \n",
    "```python -m pip install --upgrade pip```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924e1eaa",
   "metadata": {},
   "source": [
    "## Hugging Face ê°„ë‹¨í•œ ì˜ˆì œ\n",
    "\n",
    "1. Hugging Faceì™€ Gradioë¥¼ ì´ìš©í•´ì„œ ê°„ë‹¨í•œ ì§ˆì˜ì‘ë‹µì„ í•  ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ ì›¹ì•±ì„ ì‹¤í–‰í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e490f0",
   "metadata": {},
   "source": [
    "1. transformer: BERE, GPT, TS ë“± ìœ ëª…í•œ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ\n",
    "2. ì‚¬ì „í•™ìŠµ ëª¨ë¸ í—ˆë¸Œ: ì—°êµ¬ìë“¤ì´ í•™ìŠµì‹œí‚¨ ëª¨ë¸ì„ ê³µìœ í•˜ëˆˆ í”Œë«í¼\n",
    "3. ì†ì‰¬ìš´ í…ŒìŠ¤íŠ¸: íŒŒì´ì¬ ì½”ë“œë¡œ ëŒ€í˜• AI ëª¨ë¸ì„ ì‚¬ìš©ê°€ëŠ¥\n",
    "4. ë‹¤ì–‘í•œ í…ŒìŠ¤í¬ ì§€ì›: ê±°ì˜ ëª¨ë“  NLP ì‘ì—… ì§€ì›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb60e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment = pipeline(\"sentiment=analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd3d7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannalee/Documents/ì½”ë”©/huggingface-env/lib/python3.11/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9976332783699036, 'start': 0, 'end': 5, 'answer': 'Paris'}\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "qa = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", force_download=True)\n",
    "result = qa(question=\"What is the capital of France?\", context=\"Paris is the capital of France\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e494fc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannalee/Documents/ì½”ë”©/huggingface-env/lib/python3.11/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", force_download=True)\n",
    "\n",
    "def answer_question(context, question):\n",
    "    result = qa_pipeline({\n",
    "        'context' : context,\n",
    "        'question' : question\n",
    "    })\n",
    "    return result['answer']\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=answer_question,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=5, label=\"Context (ë¬¸ë§¥ ì…ë ¥)\", placeholder=\"ì—¬ê¸°ì— ë¬¸ë§¥ì„ ì…ë ¥í•˜ì„¸ìš”.\"),\n",
    "        gr.Textbox(lines=1, label=\"Question (ì§ˆë¬¸)\", placeholder=\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.\")\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Answer (ë‹µë³€)\"),\n",
    "    title=\"ğŸ¤— Hugging Face Q&A ë°ëª¨\",\n",
    "    description=\"Hugging Faceì˜ Transformers ëª¨ë¸ì„ ì´ìš©í•œ ë¬¸ë§¥ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì›¹ì•±\"\n",
    ")\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb12907",
   "metadata": {},
   "source": [
    "## DDPG ë‹¤ì°¨ì› ê³µê°„ í•™ìŠµ ë° ì‹œë®¬ë ˆì´ì…˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811dc608",
   "metadata": {},
   "source": [
    "1. **BipedalWalker-v3**ëŠ” ì—°ì† í–‰ë™ ê³µê°„ ì¤‘ ëŒ€í‘œì ì¸ ë³µì¡í•œ í™˜ê²½ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecca9a0",
   "metadata": {},
   "source": [
    "| í•­ëª©               | Pendulum-v1  | BipedalWalker-v3 |\n",
    "| ---------------- | ------------ | ---------------- |\n",
    "| ìƒíƒœ ê³µê°„ (`state`)  | 3ì°¨ì›          | 24ì°¨ì›             |\n",
    "| í–‰ë™ ê³µê°„ (`action`) | 1ì°¨ì› (1ê°œ í† í¬)  | 4ì°¨ì› (4ê°œ ë‹¤ë¦¬ ì œì–´)   |\n",
    "| ë³´ìƒ êµ¬ì¡°            | ìˆ˜ì§ ìœ ì§€ë¥¼ ìœ„í•œ ë³´ìƒ | ëª©í‘œê¹Œì§€ ê±·ëŠ” ì„±ê³¼ ê¸°ë°˜    |\n",
    "| ì¢…ë£Œ ì¡°ê±´            | ì—†ìŒ           | ë„˜ì–´ì§„ ê²½ìš° ì¡°ê¸° ì¢…ë£Œ ê°€ëŠ¥  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ccb888",
   "metadata": {},
   "source": [
    "2. í•™ìŠµì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ import í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "806e6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0663e623",
   "metadata": {},
   "source": [
    "### í™˜ê²½ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "1. BipedalWalker-v3 í™˜ê²½ì„ ë¶ˆëŸ¬ì˜¨ë’¤, í•™ìŠµì— í•„ìš”í•œ ì°¨ì›ë“¤ì„ ì •ì˜í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6490969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BipedalWalker-v3\")\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "max_action = float(env.action_space.high[0])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54faf1",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ êµ¬ì¡° ì‘ì„±\n",
    "\n",
    "1. BipedalWalker-v3 í™˜ê²½ì— ì í•©í•œ Actor ì‹ ê²½ë§ì„ PyTorchë¡œ ì •ì˜í•˜ì„¸ìš”.  \n",
    "\n",
    "(íŒíŠ¸: ìƒíƒœ â†’ í–‰ë™ ì¶œë ¥ / ì—°ì† ê³µê°„)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1f52bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.out = nn.Linear(300, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        return torch.tanh(self.out(x)) * max_action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6fbc81",
   "metadata": {},
   "source": [
    "2. Critic ë„¤íŠ¸ì›Œí¬ë¥¼ ì •ì˜í•˜ì„¸ìš”. ì…ë ¥ì€ ìƒíƒœì™€ í–‰ë™ì„ ë°›ì•„ Q-valueë¥¼ ì˜ˆì¸¡í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae2ba292",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(state_dim + action_dim, 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.out = nn.Linear(300, 1)\n",
    "\n",
    "    def forward(self, x, u):\n",
    "        x = torch.cat([x, u], 1) # 1 == dim == ì—´ë°©í–¥ == ê°€ë¡œë¡œ\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c972d0",
   "metadata": {},
   "source": [
    "### Replay Buffer êµ¬í˜„\n",
    "\n",
    "1. ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ReplayBuffer í´ë˜ìŠ¤ë¥¼ ì§ì ‘ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "- ê²½í—˜ ë°ì´í„°ë¥¼ ì €ì¥í•  ìˆ˜ ìˆì–´ì•¼ í•¨\n",
    "\n",
    "- ì €ì¥ëœ ê²½í—˜ì—ì„œ ë¬´ì‘ìœ„ë¡œ ì¼ì •ëŸ‰ì„ ìƒ˜í”Œë§í•  ìˆ˜ ìˆì–´ì•¼ í•¨\n",
    "\n",
    "- ì €ì¥ëœ ì „ì²´ ë°ì´í„°ì˜ ê°œìˆ˜ë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆì–´ì•¼ í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2771eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, size = 1000000):\n",
    "        self.buffer = deque(maxlen=size)\n",
    "    def add(self, transition):\n",
    "        self.buffer.append(transition)  # (state, action, reward, next_state, done) = (s, a, r, s', True)\n",
    "    def sample(self, batch_size):\n",
    "        samples = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*samples))\n",
    "        return (\n",
    "            torch.FloatTensor(state).to(device),\n",
    "            torch.FloatTensor(action).to(device),\n",
    "            torch.FloatTensor(reward).unsqueeze(1).to(device),\n",
    "            torch.FloatTensor(next_state).to(device),\n",
    "            torch.FloatTensor(done).unsqueeze(1).to(device)\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e69c46",
   "metadata": {},
   "source": [
    "### DDPG ì‹ ê²½ë§ê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”\n",
    "\n",
    "1. DDPGì—ì„œ ì‹ ê²½ë§ê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.  \n",
    "ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "\n",
    "- Actor, Critic, Target Actor, Target Critic ë„¤íŠ¸ì›Œí¬ë¥¼ ì •ì˜í•˜ê³  GPU ë˜ëŠ” CPUì— í• ë‹¹í•˜ì„¸ìš”.\n",
    "\n",
    "- Target ë„¤íŠ¸ì›Œí¬ëŠ” ê°ê° í•™ìŠµ ì´ˆê¸° ë„¤íŠ¸ì›Œí¬ì˜ íŒŒë¼ë¯¸í„°ë¡œ ë™ê¸°í™”ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "- Actorì™€ Criticì— ëŒ€í•´ ê°ê° ë‹¤ë¥¸ í•™ìŠµë¥ ì„ ê°–ëŠ” Adam ì˜µí‹°ë§ˆì´ì €ë¥¼ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "- ê²½í—˜ì„ ì €ì¥í•  ìˆ˜ ìˆëŠ” ReplayBuffer ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "- í• ì¸ìœ¨(gamma), íƒ€ê²Ÿ ì†Œí”„íŠ¸ ì—…ë°ì´íŠ¸ ê³„ìˆ˜(tau), ë°°ì¹˜ í¬ê¸°(batch_size), íƒí—˜ ë…¸ì´ì¦ˆ(exploration_noise)ë¥¼ ì •ì˜í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c76e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "actor = Actor().to(device)\n",
    "critic = Critic().to(device)\n",
    "target_actor = Actor().to(device)\n",
    "target_critic = Critic().to(device)\n",
    "target_actor.load_state_dict(actor.state_dict())\n",
    "target_critic.load_state_dict(critic.state_dict())\n",
    "actor_optimizer = optim.Adam(actor.parameters(), lr=1e-4)\n",
    "critic_optimizer = optim.Adam(critic.parameters(), lr=1e-3)\n",
    "replay_buffer = ReplayBuffer()\n",
    "gamma = 0.99\n",
    "tau = 0.005\n",
    "batch_size = 64\n",
    "exploration_noise = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f224994",
   "metadata": {},
   "source": [
    "2. DDPGì—ì„œ Actorì™€ Criticì„ í•™ìŠµì‹œí‚¤ëŠ” train() í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì„¸ìš”.  \n",
    "\n",
    "ë‹¤ìŒ ì¡°ê±´ì„ ì¶©ì¡±í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "\n",
    "- Replay Bufferì—ì„œ ì¼ì • ìˆ˜ ì´ìƒì˜ ë°ì´í„°ê°€ ìŒ“ì˜€ì„ ë•Œë§Œ í•™ìŠµì´ ì‹œì‘ë˜ë„ë¡ í•˜ì„¸ìš”.\n",
    "\n",
    "- Critic ë„¤íŠ¸ì›Œí¬ëŠ” íƒ€ê²Ÿ Qê°’ì„ ì‚¬ìš©í•´ MSE Lossë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•™ìŠµí•˜ì„¸ìš”.\n",
    "\n",
    "- Actor ë„¤íŠ¸ì›Œí¬ëŠ” Criticì´ ë†’ê²Œ í‰ê°€í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì •ì±…ì„ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.\n",
    "\n",
    "- í•™ìŠµ í›„, **íƒ€ê²Ÿ ë„¤íŠ¸ì›Œí¬(actor/critic)** ë¥¼ Soft Update ë°©ì‹ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.\n",
    "\n",
    "- Critic LossëŠ” ```old_critic_losses``` ë¦¬ìŠ¤íŠ¸ì—, Episode RewardëŠ” ì™¸ë¶€ì—ì„œ ```old_episode_rewards```ì— ì €ì¥ëœë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da9994d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_rewards = []\n",
    "critic_losses = []\n",
    "def train():\n",
    "    if len(replay_buffer) < batch_size:\n",
    "        return\n",
    "    \n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "    with torch.no_grad():\n",
    "        target_action = target_actor(next_state)\n",
    "        target_q = reward + (1 - done) * gamma * target_critic(next_state, target_action)\n",
    "    currnet_q = critic(state, action)\n",
    "    critic_loss = F.mse_loss(currnet_q, target_q)\n",
    "    critic_optimizer.zero_grad()\n",
    "    critic_loss.backward()\n",
    "    critic_optimizer.step()\n",
    "    critic_losses.append(critic_loss.item())\n",
    "    actor_loss = -critic(state, actor(state)).mean()\n",
    "    actor_optimizer.zero_grad()\n",
    "    actor_loss.backward()\n",
    "    actor_optimizer.step()\n",
    "\n",
    "    for param, target_param in zip(critic.parameters(), target_critic.parameters()):\n",
    "        target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
    "        \n",
    "    for param, target_param in zip(actor.parameters(), target_actor.parameters()):\n",
    "        target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc614733",
   "metadata": {},
   "source": [
    "3. DDPG í•™ìŠµ ë£¨í”„ë¥¼ ì‘ì„±í•˜ê³  í•™ìŠµì„ ì§„í–‰í•´ë³´ì„¸ìš”.\n",
    "\n",
    "ê° ì—í”¼ì†Œë“œë§ˆë‹¤ ì–»ì€ ë³´ìƒì„ ëˆ„ì í•˜ì—¬ ```old_episode_reward```ë¡œ ì €ì¥í•˜ê³ , ì´ë¥¼ ```old_episode_rewards``` ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e789567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e2fbef4",
   "metadata": {},
   "source": [
    "3. DDPG í•™ìŠµ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ê³  ëª¨ë¸ì„ ì €ì¥í•˜ì„¸ìš”. \n",
    "\n",
    "ê·¸ë˜í”„ì˜ ì œëª©ì€ ê°ê° \"Episode Rewards\", \"Critic Losses\"ë¡œ ì§€ì •í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b58193d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d73b490f",
   "metadata": {},
   "source": [
    "### í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •\n",
    "\n",
    "1. í•™ìŠµ ê²°ê³¼ ë³´ìƒì´ ```-100 ~ 0``` ì‚¬ì´ì— ìˆìŠµë‹ˆë‹¤. ìœ ì˜ë¯¸í•œ í•™ìŠµì´ ë˜ì§€ ì•Šì•˜ë‹¤ëŠ” ëœ»ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì—¬ ë‹¤ì‹œ í•™ìŠµí•´ë³´ê² ìŠµë‹ˆë‹¤.  \n",
    "\n",
    "<br>\n",
    "\n",
    "**noise**ëŠ” ```0.1 -> 0.2```ë¡œ ì¦ê°€, **episode**ëŠ” ```1000~2000``` ì‚¬ì´ë¡œ ì¡°ì •, **timestep**ì€ ```1600``` ì´í•˜ë¡œ ì„¤ì •í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c68305d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40573a8f",
   "metadata": {},
   "source": [
    "2. ë³€ê²½ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì ìš©í•˜ì—¬ ë‹¤ì‹œ í•™ìŠµì„ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤.  \n",
    "\n",
    "- í•™ìŠµì„ ì§„í–‰í•˜ëŠ” ë„ì¤‘ ìµœê³  ì„±ëŠ¥ì˜ ëª¨ë¸ì„ ì €ì¥í•˜ì„¸ìš”.\n",
    "\n",
    "- í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì €ì¥í•˜ê¸° ì´ì „ì˜ ì„±ëŠ¥ ê·¸ë˜í”„ì™€ ë¹„êµí•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08bacce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3e63bcc",
   "metadata": {},
   "source": [
    "3. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜ì„ ì§„í–‰í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc37ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
